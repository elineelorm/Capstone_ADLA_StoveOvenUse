{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Set the path for the CSV file\n",
    "path = \"C:/SmoteTest/Test.csv\"\n",
    "\n",
    "# Read the dataset from the CSV file and remove the last row\n",
    "dataset = pd.read_csv(path)\n",
    "dataset = dataset[:-1]\n",
    "print(dataset[list(dataset.columns.values)[4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets (50-50 ratio) using stratified sampling based on 'safety' attribute\n",
    "from sklearn.model_selection import train_test_split \n",
    "train, test = train_test_split(dataset, test_size=0.5, random_state=1, stratify=dataset['safety'], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "ss_train = StandardScaler()\n",
    "X_train = ss_train.fit_transform(train.iloc[:,4:])\n",
    "y_train = train.iloc[:,4]\n",
    "X_test = ss_train.transform(test.iloc[:,4:])\n",
    "y_test = test.iloc[:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First index \n",
      " [-0.98373875  0.          1.51000602  1.85406752  5.5713679   2.74894124\n",
      "  2.43950726  2.77969509  1.35778804  1.54571473  1.85469901  5.57501425\n",
      "  2.73307291  2.42527407  2.75510246  1.35764794  0.22481344  1.0224031\n",
      "  2.66682754  2.05526239  1.7012128   2.25153313  1.35769823  1.02213646\n",
      "  0.87282049  0.39139331  1.93369999  1.61951756  2.15547683  1.35764988\n",
      "  0.42772208  0.44082172 -0.13965549  1.18841165  1.11199265  1.40587692\n",
      "  1.35770037 -0.02061074 -0.01711162 -0.43205132  0.56196166  0.51954769\n",
      "  0.63044556  1.35763734 -0.19564632 -0.19240991 -0.49203012  0.22992078\n",
      "  0.20066863  0.25195864  1.3576601  -0.46096564 -0.48953506 -0.48916856\n",
      " -0.11502733 -0.18227222 -0.03198363  1.35764076 -0.68965551 -0.52930761\n",
      " -0.93517252 -0.38298785 -0.31270435 -0.5340721   1.35766969 -0.88168333\n",
      " -0.74836195 -0.9908219  -0.74332991 -0.68541459 -0.71241973  1.35765328\n",
      " -0.96594499 -0.88443096 -0.38523159 -0.79495106 -0.80868283 -0.81269581\n",
      "  1.35766627 -0.92002163 -0.96266197 -0.83135129 -0.89797913 -0.92153927\n",
      " -0.8112879   1.3576506  -0.88010204 -0.90902838 -0.36012807 -0.8840644\n",
      " -0.90575044 -0.78906521  1.35766181 -0.86465736 -0.86586873 -0.77421236\n",
      " -0.83095298 -0.85288372 -0.72666317  1.35765812 -0.86747241 -0.87434254\n",
      " -0.4674657  -0.85625812 -0.86434892 -0.78992061  1.35766288 -0.82099029\n",
      " -0.87672582 -0.82785686 -0.82230972 -0.86286849 -0.80158845  1.35765723\n",
      " -0.90113361 -0.91876213 -0.55322458 -0.89985273 -0.91019075 -0.8668947\n",
      "  1.35765349 -0.873233   -0.88306518 -0.63403337 -0.8748356  -0.88006437\n",
      " -0.86639987  1.35765213 -0.92063559 -0.92840156 -0.68293875 -0.91381248\n",
      " -0.91498598 -0.90930715  1.35764905 -0.90426302 -0.90889943 -0.67985146\n",
      " -0.90596482 -0.90841297 -0.89255346]\n",
      "Label  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"First index \\n\", X_train[0])\n",
    "print(\"Label \", y_train.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize several binary classifiers\n",
    "models = {}\n",
    "\n",
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "models['Logistic Regression'] = LogisticRegression()\n",
    "\n",
    "# Support Vector Machines\n",
    "from sklearn.svm import LinearSVC\n",
    "models['Support Vector Machines'] = LinearSVC()\n",
    "\n",
    "# Decision Trees\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "models['Decision Trees'] = DecisionTreeClassifier()\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "models['Random Forest'] = RandomForestClassifier()\n",
    "\n",
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "models['Naive Bayes'] = GaussianNB()\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "models['K-Nearest Neighbor'] = KNeighborsClassifier(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluating performance \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y_train: [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in y_train:\", y_train.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "True Positive(TP)  =  31\n",
      "False Positive(FP) =  0\n",
      "True Negative(TN)  =  30\n",
      "False Negative(FN) =  0\n",
      " \n",
      "Support Vector Machines\n",
      "True Positive(TP)  =  31\n",
      "False Positive(FP) =  0\n",
      "True Negative(TN)  =  30\n",
      "False Negative(FN) =  0\n",
      " \n",
      "Decision Trees\n",
      "True Positive(TP)  =  31\n",
      "False Positive(FP) =  0\n",
      "True Negative(TN)  =  30\n",
      "False Negative(FN) =  0\n",
      " \n",
      "Random Forest\n",
      "True Positive(TP)  =  31\n",
      "False Positive(FP) =  0\n",
      "True Negative(TN)  =  30\n",
      "False Negative(FN) =  0\n",
      " \n",
      "Naive Bayes\n",
      "True Positive(TP)  =  31\n",
      "False Positive(FP) =  0\n",
      "True Negative(TN)  =  30\n",
      "False Negative(FN) =  0\n",
      " \n",
      "K-Nearest Neighbor\n",
      "True Positive(TP)  =  31\n",
      "False Positive(FP) =  0\n",
      "True Negative(TN)  =  30\n",
      "False Negative(FN) =  0\n",
      " \n"
     ]
    }
   ],
   "source": [
    "accuracy, precision, recall, f1Score = {}, {}, {}, {}\n",
    "\n",
    "for key in models.keys():\n",
    "    \n",
    "    # Fit the classifier\n",
    "    models[key].fit(X_train, y_train)\n",
    "    # Make predictions\n",
    "    predictions = models[key].predict(X_test)\n",
    "        \n",
    "    # Calculate metrics\n",
    "    accuracy[key] = accuracy_score(predictions, y_test)\n",
    "    precision[key] = precision_score(predictions, y_test, pos_label=1)\n",
    "    recall[key] = recall_score(predictions, y_test, pos_label=1)\n",
    "    f1Score[key] = f1_score(predictions, y_test, pos_label=1)\n",
    "\n",
    "    cm = confusion_matrix(y_test, predictions, labels =[0,1])\n",
    "\n",
    "    TN, FP, FN, TP = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "    print(key)\n",
    "    print('True Positive(TP)  = ', TP)\n",
    "    print('False Positive(FP) = ', FP)\n",
    "    print('True Negative(TN)  = ', TN)\n",
    "    print('False Negative(FN) = ', FN)\n",
    "   \n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Trees</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-Nearest Neighbor</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Accuracy  Precision  Recall  F1 Score\n",
       "Logistic Regression           1.0        1.0     1.0       1.0\n",
       "Support Vector Machines       1.0        1.0     1.0       1.0\n",
       "Decision Trees                1.0        1.0     1.0       1.0\n",
       "Random Forest                 1.0        1.0     1.0       1.0\n",
       "Naive Bayes                   1.0        1.0     1.0       1.0\n",
       "K-Nearest Neighbor            1.0        1.0     1.0       1.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to display the performance metrics for each classifier\n",
    "import pandas as pd\n",
    "\n",
    "df_model = pd.DataFrame(index=models.keys(), columns=['Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "df_model['Accuracy'] = accuracy.values()\n",
    "df_model['Precision'] = precision.values()\n",
    "df_model['Recall'] = recall.values()\n",
    "df_model['F1 Score'] = f1Score.values()\n",
    "\n",
    "df_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "joe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f68e4add4496527b9674a63acba119721a637cda07cda366c24d8640169663e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
